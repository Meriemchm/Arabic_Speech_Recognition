{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset ,DataLoader\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from scipy.fftpack import idct\n",
    "from scipy.io import wavfile as wav\n",
    "from tqdm import tqdm\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" #le hardware ou on va travailler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"D:\\df\\\\ai\\\\arabic_dataset\"\n",
    "BATCH_SIZE = 16 #16 fichier dzns le batch\n",
    "LR = 0.001 #optimazer genralement 0.01\n",
    "TARGET_LEN = 22000 #taille de tout les vocaux\n",
    "K_SIZE = 3 # filter size\n",
    "LABELS = {0:\"اعجبني\",1:\"لم يعجبني\",2:\"هذا\",3:\"الفيلم\",4:\"رائع\",5:\"مقول\",6:\"سيئ\",7:\"NOISE\"} \n",
    "NUM_LABELS = len(LABELS)\n",
    "DROPOUT = 0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :1015 P:0.5\n",
      "val :406 P:0.2\n",
      "test :609 P:0.3\n"
     ]
    }
   ],
   "source": [
    "#Dataset to give it to dataloader\n",
    "class VoiceDataset(Dataset):\n",
    "    def __init__(self,data,labels,transform=False,target_length=TARGET_LEN) -> None:\n",
    "        super().__init__()\n",
    "        self.data = data \n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_length=target_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def Mel2Hz(self,mel): return 700 * (np.power(10,mel/2595)-1)\n",
    "    def Hz2Ind(self,freq,fs,Tfft): return (freq*Tfft/fs).astype(int)\n",
    "    def hamming(self,T): return 0.54-0.46*np.cos(2*np.pi*np.arange(T)/(T-1))\n",
    "    def Hz2Mel(self,freq): return 2595 * np.log10(1+freq/700)\n",
    "    def FiltresMel(self,fs, nf=36, Tfft=512, fmin=100, fmax=8000):\n",
    "        Indices=self.Hz2Ind(self.Mel2Hz(np.linspace(self.Hz2Mel(fmin), self.Hz2Mel(min(fmax,fs/2)), nf+2)),fs,Tfft)\n",
    "        filtres=np.zeros((int(Tfft/2), nf))\n",
    "        for i in range(nf): filtres[Indices[i]:Indices[i+2],i]=self.hamming(Indices[i+2]-Indices[i])\n",
    "        return filtres\n",
    "    #Réalisation d'un banc de filtres mel\n",
    "\n",
    "    #Calcul du spectrogramme\n",
    "    def spectrogram(self,x, T, p, Tfft):\n",
    "        S=[] \n",
    "        for i in range(0,len(x)-T,p): S.append(x[i:i+T]*self.hamming(T)) #fenêtrage \n",
    "        S=np.fft.fft(S,Tfft) #Transformée de Fourier\n",
    "        return np.abs(S),np.angle(S) #spectre d'amplitude et de phase\n",
    "    \n",
    "    def Mfcc(self,data, filtres, nc=13, T=256, p=64, Tfft=512):\n",
    "        data=(data-np.mean(data))/np.std(data) # normaliser les données\n",
    "        amp,ph=self.spectrogram(data, T, p, Tfft)\n",
    "        amp_f=np.log10(np.dot(amp[:,:int(Tfft/2)],filtres)+1)\n",
    "        return idct(amp_f, n=nc, norm='ortho')\n",
    "\n",
    "    def load_and_pad_audio(self,audio):\n",
    "\n",
    "        #plus 22000 deminuet la taille moins ajoute des 0\n",
    "        if len(audio) < self.target_length:\n",
    "            audio = np.pad(audio, (0, self.target_length - len(audio)), mode='constant')\n",
    "        elif len(audio) > self.target_length:\n",
    "            audio = audio[:self.target_length]\n",
    "        return audio\n",
    "\n",
    "    def __getitem__(self, index) :\n",
    "        #reading data\n",
    "        file = self.data[index] #obsolete\n",
    "        fs, sgn = wav.read(os.path.join(ROOT,\"All\",file))\n",
    "        sgn = self.load_and_pad_audio(np.array(sgn,dtype=np.float32))\n",
    "\n",
    "        #extraction des caracteristique \n",
    "        filtres=self.FiltresMel(fs)\n",
    "        if self.transform  :\n",
    "            sgn= self.Mfcc(sgn,filtres) \n",
    "\n",
    "        sgn = torch.tensor(sgn,dtype=torch.float32).to(device)\n",
    "        sgn = torch.unsqueeze(sgn, dim=0)\n",
    "\n",
    "        label = self.labels[index] #label of data \n",
    "\n",
    "        #list of the position loss fonction for result\n",
    "        oneHOt = torch.zeros(size=(8,)).to(device)  \n",
    "        oneHOt[int(label)]= 1\n",
    "\n",
    "        return sgn , oneHOt \n",
    "\n",
    "#name of data    \n",
    "def load_Data():\n",
    "    files = os.listdir(os.path.join(ROOT,\"wavs\")) \n",
    "    labels = list(map(lambda x:x.split(\"-\")[3],files))\n",
    "    return files,labels\n",
    "\n",
    "def load_noise():\n",
    "    noises = os.listdir(os.path.join(ROOT,\"noise\"))\n",
    "    labels = [7]*len(noises)\n",
    "    return noises,labels\n",
    "\n",
    "def split_data(data,labels):\n",
    "    train_data ,test_data = train_test_split(data,test_size=0.5,random_state=23) # 50% apprentissage, 20% validation, 30% test\n",
    "    train_labels ,test_labels = train_test_split(labels,test_size=0.5,random_state=23)\n",
    "    test_data ,val_data = train_test_split(test_data,test_size=0.4,random_state=23) #20/50 du test pour validation\n",
    "    test_labels ,val_labels = train_test_split(test_labels,test_size=0.4,random_state=23)\n",
    "    return (train_data,train_labels),(val_data,val_labels),(test_data,test_labels)\n",
    "\n",
    "\n",
    "data,labels = load_Data()\n",
    "noise , noise_labels = load_noise()\n",
    "\n",
    "#merge\n",
    "data += noise\n",
    "labels += noise_labels\n",
    "\n",
    "(train_data,train_labels),(val_data,val_labels),(test_data,test_labels)= split_data(data,labels) #data\n",
    "\n",
    "print(f\"train :{len(train_data)} P:{len(train_data)/len(data)}\")\n",
    "print(f\"val :{len(val_data)} P:{len(val_data)/len(data)}\")\n",
    "print(f\"test :{len(test_data)} P:{len(test_data)/len(data)}\")\n",
    "\n",
    "traindataset = VoiceDataset(train_data,train_labels,transform=True)\n",
    "testdataset = VoiceDataset(test_data,test_labels,transform=True)\n",
    "valdataset = VoiceDataset(val_data,val_labels,transform=True)\n",
    "\n",
    "#get item\n",
    "train_loader = DataLoader(traindataset,batch_size=BATCH_SIZE) #to load and batch data\n",
    "test_loader = DataLoader(testdataset,batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(valdataset,batch_size=BATCH_SIZE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        #three layers we have karnel and convolate with our matrixe and then compresse data\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=K_SIZE, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=K_SIZE, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=K_SIZE, padding=1)\n",
    "\n",
    "        #compresse matrice , elle prends le maximun dans une matrice avec un kernal de 2 \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        #fully connected layer after convolution\n",
    "        self.fc1 = nn.Linear(128*42, 256)\n",
    "\n",
    "        #output\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        #activation fonction  moins de 0 0 plus elle reste comme elle est \n",
    "        #after layer\n",
    "        self.relu = nn.ReLU()\n",
    "        #for overfitting moitier of node fermer\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #l'appelle des layers\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "\n",
    "        #flat matrices into one vecteur\n",
    "        x = x.view(-1, 128*42)\n",
    "\n",
    "        #on ferme les dernier\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        #output z donne un vecteur de 8 valeur \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "model = CNN(8).to(device) #\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 51.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.070342844352126, Val Loss :2.0103577421261716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 52.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.8190843109041452, Val Loss :1.7027249611341035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 52.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.6360711846500635, Val Loss :1.572107576406919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 52.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.516125502064824, Val Loss :1.4947517284980187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 52.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 1.4489894825965166, Val Loss :1.4233382504719954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 52.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 1.3730121115222573, Val Loss :1.3790963842318609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 52.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 1.3466647071763873, Val Loss :1.3375512178127582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 52.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 1.257273186929524, Val Loss :1.4179193056546724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 52.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 1.275877196341753, Val Loss :1.305045824784499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 53.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.2181637790054083, Val Loss :1.2879040837287903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 52.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 1.1601374363526702, Val Loss :1.2886599600315094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 53.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 1.1504869535565376, Val Loss :1.2547258390830114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 53.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 1.0886792875826359, Val Loss :1.2288319766521454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 53.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 1.0358745292760432, Val Loss :1.2212577347572033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 53.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 1.001592149026692, Val Loss :1.2228197730504549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 53.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.9593488513492048, Val Loss :1.1537467768559089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:19<00:00, 53.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.9336426854133606, Val Loss :1.134179589840082\n"
     ]
    }
   ],
   "source": [
    "def train(num_epochs,train_loader,val_loader,model):\n",
    "    criterion = nn.CrossEntropyLoss() #loss fonction calcule l'erreur and soft max\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR) #minimize loss and adam cause generale\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        pbar = tqdm(total=len(train_loader)*BATCH_SIZE)\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        val_running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad() \n",
    "            outputs = model(inputs) \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step() #obliger\n",
    "            running_loss += loss.item() #valeur de loss\n",
    "            pbar.update(BATCH_SIZE)\n",
    "\n",
    "        pbar.close()\n",
    "\n",
    "        #calculate validation loss \n",
    "        #overfitting or not , hyperparametters \n",
    "        for inputs , labels in val_loader :\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs,labels)\n",
    "            val_running_loss += val_loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Val Loss :{val_running_loss/len(val_loader)}\")\n",
    "    return model\n",
    "\n",
    "model = train(17,train_loader,val_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :\n",
      "accuray is : 0.8236453201970443\n",
      "f1score is : 0.8236453201970443\n",
      "[[123   4   2   1   2   1   0   0]\n",
      " [  1 124   0   2   1   1   2   0]\n",
      " [  2   2  91   0  49   0   0   0]\n",
      " [ 14  20   0  83   0   6   3   0]\n",
      " [  1   0  15   0 141   0   1   0]\n",
      " [ 13   3   2   8   1 103   2   0]\n",
      " [  0  13   0   7   0   0 120   0]\n",
      " [  0   0   0   0   0   0   0  51]]\n",
      "testing :\n",
      "accuray is : 0.638752052545156\n",
      "f1score is : 0.638752052545156\n",
      "[[66  7  3  6  2  2  0  0]\n",
      " [ 4 71  1  4  0  0  0  0]\n",
      " [ 5  0 45  0 58  3  0  0]\n",
      " [16 19  0 34  1  6  3  0]\n",
      " [ 0  0 15  0 59  0  0  0]\n",
      " [22  5  4  5  1 40  3  0]\n",
      " [ 1 13  1  5  2  3 49  0]\n",
      " [ 0  0  0  0  0  0  0 25]]\n"
     ]
    }
   ],
   "source": [
    "def Metrices(loader,model):\n",
    "    model.eval() #ne rien faire\n",
    "    preds = []\n",
    "    real = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x , y in loader :\n",
    "            x = x.to(device=device) #mfcc\n",
    "            y = y.to(device=device) #la valeur output 0,8\n",
    "            out = model(x)\n",
    "            pred = torch.argmax(out,dim=1)\n",
    "            y = torch.argmax(y,dim=1) #valeur de la probabilite la plus garnde\n",
    "            pred = pred.to(\"cpu\").numpy() #cpu for numpy\n",
    "            y = y.to(\"cpu\").numpy()\n",
    "            preds+=list(pred)\n",
    "            real+=list(y)\n",
    "           \n",
    "    acc = accuracy_score(preds,real)\n",
    "    f1 = f1_score(preds,real,average='micro')\n",
    "    cm = confusion_matrix(real,preds)\n",
    "    print(f\"accuray is : {acc}\")\n",
    "    print(f\"f1score is : {acc}\")\n",
    "    print(cm)\n",
    "    model.train()\n",
    "    return acc,f1,cm\n",
    "\n",
    "print(\"Train :\")\n",
    "train_acc ,train_f1,cm = Metrices(train_loader,model)\n",
    "print(\"testing :\")\n",
    "acc,f1,cm = Metrices(test_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write hyperprameters and there accuracy\n",
    "with open(\"results.txt\",\"a\") as file:\n",
    "    file.write(f\"Train_acc:{train_acc},test_accuracy :{acc}\\tf1:{f1}\\tbatch_size:{BATCH_SIZE}\\tlearningRate:{LR}\\tdropoutRate:{DROPOUT}\\tkernel_size:{K_SIZE}\\n\")\n",
    "torch.save(model.state_dict(),f\"models/{acc}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
